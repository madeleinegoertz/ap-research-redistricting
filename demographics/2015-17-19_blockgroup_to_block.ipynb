{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've downloaded a bunch of yearly ACS data from the IPUMS NHGIS, but since this is only a 5 year average of a sample survey, the smallest geographic unit reported at is the block group, not the block. \n",
    "\n",
    "However, blocks nest nicely into block groups, so I should be able to disaggregate from block groups to blocks using maup and prorating by total population, which seems like a reasonable assumption to make."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `ADK5E001` = `pop`: Total population\n",
    "* `ADK5E001` = `TotPop`: Total population (again)\n",
    "* `ADK5E004` = `BlackPop`: Total Black population\n",
    "* `ADK5E012` = `HispPop`: Total Hispanic Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import numpy as np\n",
    "import maup\n",
    "import warnings\n",
    "\n",
    "maup.progress.enabled = True\n",
    "\n",
    "# Create block group level shp file with population and vap data\n",
    "# Block group shp is constant throughout decade, so that's not passed in\n",
    "# vap_f_name = str, file name of zipped csv with VAP by race data (downloaded from Census)\n",
    "# out_f_name = str, path where to write shp file, must be .shp\n",
    "def blck_grp_merge_vap(vap_f_name, out_f_name):\n",
    "    # read in blocks shapefile, stays same every year\n",
    "    blck_grp = geopandas.read_file(\"zip://C:/Users/madie/OneDrive/data/ipums/VA_blck_grp_2019.zip\")\n",
    "    # keep only the useful cols\n",
    "    blck_grp = blck_grp[[\"GEOID\", \"GISJOIN\", \"geometry\"]].copy()\n",
    "    # read in population data csv\n",
    "    data = pd.read_csv(\"C:/Users/madie/OneDrive/data/ipums/VA_blck_grp_2015_pop.zip\")\n",
    "    # keep only the relevant columns for total Black and Hispanic population (and vap)\n",
    "    data = data[[\"GISJOIN\", \"ADK5E001\", \"ADK5E001\", \"ADK5E004\", \"ADK5E012\"]].copy()\n",
    "    # rename these cols to something more intelligible\n",
    "    data.columns = [\"GISJOIN\", \"pop\", \"TotPop\", \"BlackPop\", \"HispPop\"]\n",
    "    # merge the population data into the blocks shapefile\n",
    "    blck_grp = blck_grp.merge(data, on='GISJOIN')\n",
    "\n",
    "    #read in csv file with vap data\n",
    "    vap = pd.read_csv(vap_f_name, encoding=\"latin1\")\n",
    "    # split up GEONAME columns on commas into 4 different things\n",
    "    vap[[\"blck_grp\", \"tract\", \"county\", \"state\"]] = vap[\"GEONAME\"].str.split(pat=\",\", expand=True)\n",
    "    # remove leading and trailing spaces from state col\n",
    "    vap['state'] = vap['state'].str.strip()\n",
    "    # filter to only incude virginia block groups\n",
    "    vap = vap.loc[vap['state'] == \"Virginia\"]\n",
    "    # group by unique identifier then by racial group\n",
    "    vap = vap.set_index(['geoid', \"lnnumber\"])\n",
    "    vap = vap[[\"CVAP_EST\"]]\n",
    "    # \"pivot\" with geoid as row and lnnumber (race) as col\n",
    "    df_vap = vap.unstack()\n",
    "    # remove top level col name\n",
    "    df_vap = df_vap.droplevel(None, axis=1)\n",
    "    df_vap.columns.name = None\n",
    "    df_vap = df_vap.reset_index()\n",
    "    # filter to only include geoid, total, Black, Hispanic\n",
    "    df_vap = df_vap.filter(items=[\"geoid\", 1, 5, 13])\n",
    "    # rename cols\n",
    "    df_vap.columns = [\"geoid\", \"VAP\", \"BlackVAP\", \"HISPVAP\"]\n",
    "    # reformat geoid to match that in other table\n",
    "    df_vap[[\"prefix\", \"GEOID\"]] = df_vap[\"geoid\"].str.split(pat=\"US\", expand=True)\n",
    "    df_vap = df_vap.drop(columns=[\"prefix\", \"geoid\"])\n",
    "\n",
    "    # merge in VAP\n",
    "    blck_grp = blck_grp.merge(df_vap, on='GEOID')\n",
    "    # write to shp file\n",
    "    blck_grp.to_file(out_f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2015: done, 2017: done, 2019: done\n",
    "vap_f_name = \"C:/Users/madie/OneDrive/data/census/VA_blockgroup_2015-2019_vap.zip\" # change for year\n",
    "out_f_name = \"C:/Users/madie/OneDrive/data/blck_grp/VA_blck_grp_2019_pop_vap.shp\" # change for year\n",
    "blck_grp_merge_vap(vap_f_name, out_f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to disaggregate from the block group level down to the block level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# turn off annoying geoseries isna warnings\n",
    "warnings.filterwarnings('ignore', 'GeoSeries.isna', UserWarning)\n",
    "\n",
    "# Given block groups, disaggregate down to block level, prorating by total relative population \n",
    "# Blocks shp are constant throughout decade, so not passed in\n",
    "# blck_grp_f_name = str, file name of zipped block group level shp file\n",
    "# out_f_name = str, path where to write final block level shp file, must end in .shp\n",
    "def disaggregate(blck_grp_f_name, out_f_name):\n",
    "    # read in files\n",
    "    blck_grp = geopandas.read_file(blck_grp_f_name)\n",
    "    blocks = geopandas.read_file(\"zip://C:/Users/madie/OneDrive/data/ipums/VA_block_2010_pop.zip\")\n",
    "    # remove unnecessary colmns\n",
    "    blocks = blocks.drop(columns=[\"vap\", \"TotPop\", \"BlackPop\", \"HispPop\", \"VAP_1\", \"BlackVAP\", \"HispVAP\"])\n",
    "\n",
    "    # change crs of shp files to be projected (using VA north)\n",
    "    blocks = blocks.to_crs(epsg=2283)\n",
    "    blck_grp = blck_grp.to_crs(epsg=2283)\n",
    "    # remove any bowties (little imperfections in the polygons)\n",
    "    blocks.geometry = blocks.buffer(0)\n",
    "    blck_grp.geometry = blck_grp.buffer(0)\n",
    "    # reset indices\n",
    "    blocks = blocks.reset_index(drop = True)\n",
    "    blck_grp = blck_grp.reset_index(drop = True)\n",
    "\n",
    "    # assign blocks to block groups\n",
    "    pop_cols = [\"pop\", \"TotPop\", \"BlackPop\", \"HispPop\", \"VAP\", \"BlackVAP\", \"HISPVAP\"]\n",
    "    assignment = maup.assign(blocks, blck_grp)\n",
    "    # We prorate the population totals according to each block's share of the overall\n",
    "    # block group population:\n",
    "    denom = assignment.map(blck_grp[\"pop\"])\n",
    "    weights = blocks[\"pop\"] / denom\n",
    "    prorated = maup.prorate(assignment, blck_grp[pop_cols], weights)\n",
    "\n",
    "    # Add the prorated vote totals as columns on the `blocks` GeoDataFrame:\n",
    "    blocks[pop_cols] = prorated\n",
    "    blocks.to_file(out_f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5321/5321 [02:10<00:00, 40.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5321/5321 [06:57<00:00, 12.75it/s]\n"
     ]
    }
   ],
   "source": [
    "blck_grp_f_name = \"zip://C:/Users/madie/OneDrive/data/blck_grp/VA_blck_grp_2017_pop_vap.zip\"\n",
    "out_f_name = \"C:/Users/madie/OneDrive/data/ipums/VA_block_2017_data/VA_block_2017_data.shp\"\n",
    "disaggregate(blck_grp_f_name, out_f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5321/5321 [02:16<00:00, 38.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5321/5321 [07:39<00:00, 11.58it/s]\n"
     ]
    }
   ],
   "source": [
    "blck_grp_f_name = \"zip://C:/Users/madie/OneDrive/data/blck_grp/VA_blck_grp_2019_pop_vap.zip\"\n",
    "out_f_name = \"C:/Users/madie/OneDrive/data/ipums/VA_block_2019_data/VA_block_2019_data.shp\"\n",
    "disaggregate(blck_grp_f_name, out_f_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
